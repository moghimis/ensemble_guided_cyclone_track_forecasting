{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EGCTF Main Module\n",
    "\n",
    "*This is the main-module which contains the EGCTF algorithm and its sub-functions. This module is to be executed prior to invoking the EGCTF algorithm. See the `test_one_case` script for an example of how to utilize this module. This file need not be modified unless the user wishes to make some deeper changes in the EGCTF algorithm.*\n",
    "\n",
    "**External Dependencies**: Python modules: `scipy`, `sklearn`, `geopy` (requires `pip install`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import copy\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta  \n",
    "import os\n",
    "from scipy import interpolate\n",
    "from scipy import optimize\n",
    "import random\n",
    "import geopy.distance\n",
    "import numpy as np\n",
    "from scipy.interpolate import Akima1DInterpolator\n",
    "from sklearn import datasets, linear_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_ensemble(ensTracks, ens_wts):\n",
    "    \"\"\" Calculate mean-ensemble track (locations) given the enseble tracks and ensemble weights.\"\"\"\n",
    "    ens_wts = np.array(ens_wts) / np.sum(ens_wts)\n",
    "    mens = np.zeros(ensTracks[0].shape)\n",
    "    for tn in range(0,nens):\n",
    "        mens = mens + ensTracks[tn]*ens_wts[tn]\n",
    "    return mens\n",
    "\n",
    "def track_position_akima(t_x, t_y, t_t, t):\n",
    "    \"\"\" Return Akima interpolated track (ensemble, or best tracks) position at arbitrary time 't' given the track sparse data points (6 hrs interval) using Akima interpolation \"\"\"\n",
    "    akx = Akima1DInterpolator(t_t, t_x)\n",
    "    aky = Akima1DInterpolator(t_t, t_y)\n",
    "    return [akx(t), aky(t), t]\n",
    "\n",
    "\n",
    "def recalc_ens_weights(known_storm_position, dud_obs, ens_wts, ensTracks, forecast_periods, senFPr, r_f):    \n",
    "    \"\"\" (Re)Calculate set of optimal ensemble weights from (1) Known Storm positions, (2) Position of failed Observations,\n",
    "        and (3) Previous set of ensemble weights\n",
    "        Input Parameters (4) forcast periods, (5) sensor footprint radius are constant.\n",
    "    \"\"\"\n",
    "    x0 = ens_wts # current ensemble weights used as intiial value in the optimization parameters\n",
    "    lbd = np.ones((nens,1))*0.005/nens # lower bound for the optimization parameters\n",
    "    ubd = np.ones((nens,1)) # upper bound\n",
    "    bnds = np.hstack((lbd, ubd)) # ensemble weights must be positive\n",
    "   \n",
    "    # run the L-BFGS-B optimizer to find the optimal optimization parameter (ensemble weights) \n",
    "    optres = optimize.minimize(optfunc, x0, args=(ensTracks, forecast_periods, known_storm_position), method='L-BFGS-B', bounds = bnds, options={'maxiter': 10000})\n",
    "    ens_wts = optres.x\n",
    "    ens_wts = np.array(ens_wts) / np.sum(ens_wts)\n",
    "    \n",
    "    # penalize the ensemble tracks close to the failed-observation points\n",
    "    ens_wts = penalize_ensTcks_close_failedObs(ens_wts, ensTracks, dud_obs, forecast_periods, senFPr, r_f)\n",
    "\n",
    "    return ens_wts\n",
    "\n",
    "def penalize_ensTcks_close_failedObs(ens_wts, ensTracks, dud_obs, forecast_periods, senFPr, r_f):\n",
    "    \"\"\" Penalize ensemble tracks close to the failed-observation position. \"\"\"    \n",
    "    nens = ensTracks.shape[0]\n",
    "    \n",
    "    # iterate over all failed observations\n",
    "    for fobs in dud_obs:\n",
    "        fobs_t = fobs[2]\n",
    "        \n",
    "        # calculate distance between failed observation point and all other ensembles\n",
    "        for k in range(0,nens):            \n",
    "            etck_x = list(ensTracks[k][:,2]) \n",
    "            etck_y = list(ensTracks[k][:,3])\n",
    "            etck_t = forecast_periods\n",
    "            etcki = track_position_akima(etck_x, etck_y, etck_t, fobs_t) # ensemble-track positions at the time of failed-observation\n",
    "    \n",
    "            d_ens_obs = np.linalg.norm(np.array(etcki[0:2])-np.array(fobs[0:2]))\n",
    "            ens_wts[k] = ens_wts[k]*np.exp(d_ens_obs*r_f) # penalize small distances       \n",
    "\n",
    "    ens_wts = np.array(ens_wts) / np.sum(ens_wts) # normalize the ensemble weights\n",
    "\n",
    "    return ens_wts\n",
    "    \n",
    "    \n",
    "def optfunc(ens_wts, ensTracks, forecast_periods, known_storm_position):\n",
    "    ''' Input function to the optimizer implemented in recalc_ens_weights function.\n",
    "        Note that the optimzation parameters are the potentially non-normalized ensemble weights.\n",
    "    '''\n",
    "    ens_wts = np.array(ens_wts) / np.sum(ens_wts)\n",
    "    \n",
    "    # calculate total(over time) error between mean track and observed track from 1st storm observation until last storm observation\n",
    "    mean_track = mean_ensemble(ensTracks, ens_wts)\n",
    "    mtck = np.hstack((mean_track[:,2:4], np.array(forecast_periods).reshape(-1,1))) # mean track\n",
    "    \n",
    "    cost = calculate_error(known_storm_position, mtck)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def calculate_track_slope(tck, time1, time2):\n",
    "    ''' time2 > time1, time2 is the forecast time, \n",
    "        time1 is the time at which the forecast is made (previous observation time)\n",
    "    '''\n",
    "    pos1 = track_position_akima(tck[:,0], tck[:,1], tck[:,2], time1)\n",
    "    pos2 = track_position_akima(tck[:,0], tck[:,1], tck[:,2], time2)\n",
    "    dt = pos2[2] - pos1[2]\n",
    "    vx = (pos2[0] - pos1[0])/dt\n",
    "    vy = (pos2[1] - pos1[1])/dt\n",
    "    return[vx, vy]\n",
    "\n",
    "def calculate_kstp_slope(known_storm_position):\n",
    "    \"\"\" Calculate slope of the track formed by previous known storm center positions.\"\"\"\n",
    "    lastIndx = known_storm_position.shape[0]-1\n",
    "    pos1 = known_storm_position[lastIndx-1]\n",
    "    pos2 = known_storm_position[lastIndx]\n",
    "    dt = pos2[2] - pos1[2]\n",
    "    vx = (pos2[0] - pos1[0])/dt\n",
    "    vy = (pos2[1] - pos1[1])/dt\n",
    "    return[vx, vy]\n",
    "\n",
    "def calculate_error(known_storm_position, tck):\n",
    "    ''' Calculate average of the errors over between the known storm positions and the input track.\n",
    "    '''\n",
    "    if(known_storm_position.size==0):\n",
    "        return 0\n",
    "    t_fine = known_storm_position[:,2]\n",
    "    tck_fine = track_position_akima(tck[:,0], tck[:,1], tck[:,2], t_fine)\n",
    "    ksps = [known_storm_position[:,0], known_storm_position[:,1], known_storm_position[:,2]]\n",
    "    error = np.sum(np.linalg.norm(np.array(ksps[0:2])-np.array(tck_fine[0:2])) )\n",
    "    error = error/known_storm_position.size\n",
    "    return error\n",
    "\n",
    "def mid_point_regressed_line(Xsamples, Ysamples, time):\n",
    "    ''' Mid-point of the regressed line.\n",
    "    '''\n",
    "     # Create linear regression object\n",
    "    regrX = linear_model.LinearRegression()\n",
    "    regrY = linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regrX.fit(time.reshape(-1,1), Xsamples.reshape(-1,1))\n",
    "    regrY.fit(time.reshape(-1,1), Ysamples.reshape(-1,1))\n",
    "\n",
    "    # find known storm position at some point on and in the middle of the regressed line\n",
    "    tmid = time[0] + 0.5 * (time[-1] - time[0])\n",
    "    xmid = regrX.predict(tmid.reshape(-1,1)).flatten()\n",
    "    ymid = regrY.predict(tmid.reshape(-1,1)).flatten()\n",
    "\n",
    "    return [xmid[0], ymid[0], tmid]\n",
    "\n",
    "def calculate_track_slope(tck, time1, time2):\n",
    "    ''' time2 > time1, time2 is the forecast time, \n",
    "        time1 is the time at which the forecast is made (previous observation time)\n",
    "    '''\n",
    "    pos1 = track_position_akima(tck[:,0], tck[:,1], tck[:,2], time1)\n",
    "    pos2 = track_position_akima(tck[:,0], tck[:,1], tck[:,2], time2)\n",
    "    dt = pos2[2] - pos1[2]\n",
    "    vx = (pos2[0] - pos1[0])/dt\n",
    "    vy = (pos2[1] - pos1[1])/dt\n",
    "    return[vx, vy]\n",
    "\n",
    "def calculate_kstp_slope(known_storm_position):\n",
    "    \"\"\" Calculate the slope of the track formed by the known-storm positions. \"\"\"\n",
    "    lastIndx = known_storm_position.shape[0]-1\n",
    "    pos1 = known_storm_position[lastIndx-1]\n",
    "    pos2 = known_storm_position[lastIndx]\n",
    "    dt = pos2[2] - pos1[2]\n",
    "    vx = (pos2[0] - pos1[0])/dt\n",
    "    vy = (pos2[1] - pos1[1])/dt\n",
    "    return[vx, vy]\n",
    "\n",
    "def process_raw_storm_center_data(raw_storm_position, regr_seg_gap_hrs, regr_subseg_length_hrs, \n",
    "                                  segment_num, segment_raw_data_indices):\n",
    "    \"\"\" Process the raw storm center data and get estimated storm center positions. \n",
    "        The raw onservation would yield noisy storm center position acquisitions. The return vector has the *estimated* storm center\n",
    "        positions at the observation times when the storm center had been captured.\n",
    "        Note that while the length of segment is variable, the length of the subsegment is always fixed.\n",
    "    \"\"\"\n",
    "    est_storm_position = [] # estimated storm positions from the raw storm positions\n",
    "    segment_data = {} # contains raw storm info of relevant segment\n",
    "    min_dps_regrss = 1 # minimum number of datapoints required per segment\n",
    "    \n",
    "    ''' Decide the segment indices, based on the gap length between the data points. \n",
    "        A gap of more than 'regr_seg_gap_hrs' wwill result in start of a new segment.\n",
    "    '''\n",
    "    raws =  raw_storm_position[~np.isnan(raw_storm_position).any(axis=1)] # drop nans\n",
    "    \n",
    "    last_valid_acq_time = raws[-1][2]    \n",
    "    #print('regr_seg_gap_hrs: ', regr_seg_gap_hrs)\n",
    "    if(raws.shape[0]>1):        \n",
    "        secondlast_valid_acq_time = raws[-2][2]\n",
    "\n",
    "        if(last_valid_acq_time - secondlast_valid_acq_time >= regr_seg_gap_hrs):\n",
    "            segment_num = segment_num + 1 # start new segment\n",
    "            \n",
    "    if(segment_num == 0):\n",
    "        segment_raw_data_indices[int(segment_num)] = [0, raws.shape[0]]\n",
    "    else:\n",
    "        segment_raw_data_indices[int(segment_num)] = [segment_raw_data_indices[int(segment_num)-1][1], raws.shape[0]]\n",
    "\n",
    "    #print('---------------------------------------------')\n",
    "    #print('segment_raw_data_indices')\n",
    "    #print(segment_raw_data_indices)\n",
    "    \n",
    "    ''' Using the segment raw data indices, make estimated (also termed as known) storm interpolation points.\n",
    "        Create subsegments when the segment is too long and find a regressed line fitting the subsegment.\n",
    "        The midpoint of the regressed line serves as a interpolation data-point for the storm center.'''\n",
    "    # iterate over each segment\n",
    "    for seg_i in range(0,len(segment_raw_data_indices)):\n",
    "        segment_data = raws[segment_raw_data_indices[seg_i][0]:segment_raw_data_indices[seg_i][1]]\n",
    "        \n",
    "        seg_num_data_pts = segment_data.shape[0]\n",
    "        segment_data_start_time = segment_data[0,2]\n",
    "        segment_data_end_time = segment_data[seg_num_data_pts-1,2]\n",
    "        #print('segment_data')\n",
    "        #print(segment_data) \n",
    "        \n",
    "        if(seg_num_data_pts >= min_dps_regrss): # minimum of 1 data-points needed per segment.                 \n",
    "            \n",
    "            segment_len_hrs = segment_data[seg_num_data_pts-1][2] - segment_data[0][2] \n",
    "            #print('segment_len_hrs: ', segment_len_hrs)\n",
    "            \n",
    "            # break into sub segments of length 'regr_subseg_length_hrs'. Note the use of ceil.\n",
    "            num_sub_segments = int(np.ceil(segment_len_hrs/regr_subseg_length_hrs))\n",
    "            #print('num_sub_segments: ', num_sub_segments)\n",
    "            \n",
    "            # iterate over all sub-segments except the last one. The last one is treated differently.\n",
    "            sseg_i = 0\n",
    "\n",
    "            # note that the last subsegment is treated differently\n",
    "            for sseg_i in range(0,num_sub_segments-1):\n",
    "                #subseg_data = np.where((segment_data[:,2]>= sseg_i*segment_data_start_time and segment_data[:,2]< (sseg_i+1)*segment_data_start_time))\n",
    "                subseg_data = segment_data[ segment_data[:,2]>= segment_data_start_time + sseg_i*regr_subseg_length_hrs]\n",
    "                subseg_data = subseg_data[ subseg_data[:,2]<= segment_data_start_time + (sseg_i+1)*regr_subseg_length_hrs ]\n",
    "                #print('subseg_data')\n",
    "                #print(subseg_data)\n",
    "                # create a known storm position at the mid-points of a line regressed over the points of the subsegement\n",
    "                if(subseg_data.shape[0] >= min_dps_regrss):\n",
    "                    if(subseg_data.shape[0] == 1):\n",
    "                        est_storm_position.append([subseg_data[:,0], subseg_data[:,1], subseg_data[:,2]])\n",
    "                    else:\n",
    "                        [estStmPosX, estStmPosY, estStmPosT] = mid_point_regressed_line(subseg_data[:,0], subseg_data[:,1], subseg_data[:,2])\n",
    "                        est_storm_position.append([ estStmPosX, estStmPosY, estStmPosT])\n",
    "\n",
    "            # for the last subsegment, reference is from the end of the segment\n",
    "            sseg_i = sseg_i + 1\n",
    "            subseg_data = segment_data[ segment_data[:,2]>= segment_data_end_time - regr_subseg_length_hrs]\n",
    "            #print('subseg_data')\n",
    "            #print(subseg_data)\n",
    "            if(subseg_data.shape[0] >= min_dps_regrss):\n",
    "                [estStmPosX, estStmPosY, estStmPosT] = mid_point_regressed_line(subseg_data[:,0], subseg_data[:,1], subseg_data[:,2])\n",
    "                est_storm_position.append([estStmPosX, estStmPosY, estStmPosT])\n",
    "            \n",
    "    est_storm_position = np.array(est_storm_position, dtype=object)\n",
    "    \n",
    "    #print('est_storm_position')\n",
    "    #print(est_storm_position)\n",
    "\n",
    "    return [est_storm_position, segment_num, segment_raw_data_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo(ensTracks, bestTrack, aemnTrack, obs_times, senFPr, obsErr, forecast_periods, nens, \n",
    "         extrpl_lastKnown_thresh, regr_seg_gap_hrs, regr_subseg_length_hrs, wetp, r_f, extrpl_numKnown_thresh):\n",
    "    \"\"\"\n",
    "    @param ensTracks: Ensemble track data\n",
    "    \n",
    "    @param bestTrack: Best track data\n",
    "    \n",
    "    @param aemnTrack: Mean ensemble track (AEMN track) data\n",
    "    \n",
    "    @param obs_times: Vector of observation times (opportunities) over which the algorithm is iterated.\n",
    "    \n",
    "    @param senFPr: sensor footprint radius in meters\n",
    "    \n",
    "    @param obsErr: Instrument observation error in [m^2]. Variance (hence [m^2]) from actual position\n",
    "    \n",
    "    @param nens: Number of ensembles\n",
    "    \n",
    "    @param extrpl_lastKnown_thresh: (Algorithm parameter) Threshold time-period since the last time the storm was seen in hours.  \n",
    "    \n",
    "    @param regr_seg_gap_hrs: (Algorithm parameter) Threshold gap between the segments in hours.\n",
    "    \n",
    "    @param regr_subseg_length_hrs: (Algorithm parameter) Subsegment length in hours.\n",
    "    \n",
    "    @param wetp: (Algorithm parameter) Weight assigned to the slope of the optimal mean ensmble track during extrapolation (1-wetp) is assigned to the slope from the last known storm-positions\n",
    "    \n",
    "    @param r_f: (Algorithm parameter) Reward factor (related to penalization factor for penalizing ensemble tracks close to failed observations)\n",
    "    \n",
    "    @param extrpl_numKnown_thresh: (Algorithm parameter) number of storm center estimations to be made after which extrapolation can start\n",
    "    \n",
    "    \"\"\"\n",
    "    storm_radius = 100e3 # [meters] Storm radius \n",
    "    timeSinceLastKnown = np.inf\n",
    "    \n",
    "    ntst = len(forecast_periods)\n",
    "\n",
    "    # initialize weigths of the ensembles\n",
    "    ens_wts = np.ones((nens, 1))\n",
    "    ens_wts = ens_wts/ np.sum(ens_wts)\n",
    "    ens_wts_met1 = np.ones((nens, 1))\n",
    "    ens_wts_met1 = ens_wts/ np.sum(ens_wts)                  \n",
    "\n",
    "    ens_wts0 = np.ones((nens, 1))\n",
    "    ens_wts0 = ens_wts0/ np.sum(ens_wts0)\n",
    "    mean0_track = mean_ensemble(ensTracks, ens_wts0)\n",
    "\n",
    "    bt_x = list(bestTrack[:,2]) # get best-track info\n",
    "    bt_y = list(bestTrack[:,3])\n",
    "    bt_t = forecast_periods\n",
    "\n",
    "    nobs = len(obs_times)\n",
    "\n",
    "    obs_positions =  np.full((nobs, 3), np.nan) # list to recored the observed positions\n",
    "    seen = np.full((nobs, 1), np.nan)  # list of storm seen or not \n",
    "    raw_storm_position =  np.full((nobs, 3), np.nan) # note that raw storm position may not be same as the actual storm position due to errors in calculation from the sensed observation data\n",
    "    raw_storm_position_error =  np.full((nobs, 1), np.nan) \n",
    "    known_storm_position =  np.array([]) \n",
    "    bt_positions =  np.full((nobs, 3), np.nan) # list to recored the best/ true positions corresponding to the observation times\n",
    "\n",
    "    segment_raw_data_indices = {}  # contains indices mappting to raw storm info array (with dropped NaNs) \n",
    "    segment_num = int(0)\n",
    "    nksp = 0 # initilize number of known storm positions\n",
    "\n",
    "    d_obs_bt =  np.full((nobs, 1), np.inf) # list of distances from observation point to best track at the observed times\n",
    "    d_aemn_bt =  np.full((nobs, 1), np.inf) # list of distances from aemn track positions (~mens0) to best track at the observed times\n",
    "\n",
    "    # iterate over the observation times\n",
    "    for indx in range(0,nobs):\n",
    "\n",
    "        obsti = obs_times[indx] # instant of observation for the current iteration\n",
    "\n",
    "        ''' calculate observation point based on previous ensemble weights and past storm track if known''' \n",
    "        mean_track = mean_ensemble(ensTracks, ens_wts)\n",
    "        mtck = np.hstack((mean_track[:,2:4], np.array(forecast_periods).reshape(-1,1)))\n",
    "        mtck_x = list(mean_track[:,2]) \n",
    "        mtck_y = list(mean_track[:,3])\n",
    "        mtck_t = forecast_periods\n",
    "        mtcki = np.array(track_position_akima(mtck_x, mtck_y, mtck_t, obsti)).flatten()\n",
    "\n",
    "        currTime = obsti\n",
    "        if(nksp>0):\n",
    "            timeSinceLastKnown = currTime - known_storm_position[-1][2]\n",
    "\n",
    "        if(nksp >= extrpl_numKnown_thresh and timeSinceLastKnown <= extrpl_lastKnown_thresh): #method2\n",
    "            # extrapolate the Known storm track to the current time\n",
    "            last_known_position = known_storm_position[known_storm_position.shape[0] -1]\n",
    "            slope_mtck = (calculate_track_slope(mtck, last_known_position[2], obsti))\n",
    "            slope_lkstp = (calculate_kstp_slope(known_storm_position))\n",
    "\n",
    "            dt = obsti - last_known_position[2] \n",
    "            dx = (wetp*slope_mtck[0] + (1-wetp)*slope_lkstp[0])*dt\n",
    "            dy = (wetp*slope_mtck[1] + (1-wetp)*slope_lkstp[1])*dt\n",
    "            obs_positions[indx][0] = last_known_position[0] + dx\n",
    "            obs_positions[indx][1] = last_known_position[1] + dy\n",
    "            obs_positions[indx][2] = obsti    \n",
    "            \n",
    "        else:\n",
    "            obs_positions[indx] = mtcki\n",
    "\n",
    "        ''' Begin Environmental simulation\n",
    "            Below part of code is for simulation only. In practise info on the storm being observed or not is obtained from \n",
    "            the onboard processor which analyses the obtained image/ observation. \n",
    "        '''    \n",
    "        bt_t = forecast_periods\n",
    "        bti = track_position_akima(bt_x, bt_y, bt_t, obsti) # get the true storm position at observation time \n",
    "        bt_positions[indx] = bti\n",
    "\n",
    "        # calculate the distance 'd' between the true storm position and the observation point\n",
    "        d = np.linalg.norm(np.array(obs_positions[indx][0:2])-np.array(bti[0:2])) \n",
    "        if(d <  senFPr): \n",
    "            seen[indx] = True\n",
    "            cov =  [[obsErr, 0], [0, obsErr]]  \n",
    "            x, y = np.random.multivariate_normal(bti[0:2], cov).T\n",
    "            raw_storm_position[indx][0] = x\n",
    "            raw_storm_position[indx][1] = y\n",
    "            raw_storm_position[indx][2] = bti[2]\n",
    "            raw_storm_position_error[indx] = np.linalg.norm(np.array(raw_storm_position[indx][0:2])-np.array(bti[0:2]))  # log error\n",
    "            ''' Substitute this snippet to simulate the case of 'no error in storm position acquisition'.\n",
    "            raw_storm_position[indx] =  np.array(bti[0:3])\n",
    "            known_storm_position = raw_storm_position\n",
    "            '''\n",
    "            ''' Process the raw storm information.\n",
    "            '''     \n",
    "            [known_storm_position, segment_num, segment_raw_data_indices] = process_raw_storm_center_data(raw_storm_position, regr_seg_gap_hrs, regr_subseg_length_hrs, \n",
    "                                                             segment_num, segment_raw_data_indices)\n",
    "\n",
    "            nksp = known_storm_position.shape[0]\n",
    "\n",
    "        else:\n",
    "            seen[indx] = False\n",
    "            raw_storm_position[indx] =  np.nan\n",
    "            raw_storm_position_error[indx] = np.nan\n",
    "        '''End of environmental simulation '''      \n",
    "\n",
    "        ''' Recalcuate the ensemble weights from new knowlwedge of the observation made'''\n",
    "        dud_obs = obs_positions[np.where(seen==0)[0]] # dud observations\n",
    "        _ens_wts = recalc_ens_weights(known_storm_position, dud_obs, ens_wts, ensTracks, forecast_periods, senFPr, r_f)\n",
    "\n",
    "        ens_wts = _ens_wts\n",
    "               \n",
    "        ''' record metrics wrt to the aemn track to evaluate the algorithm ''' \n",
    "        d_obs_bt[indx] = np.linalg.norm(np.array(obs_positions[indx][0:2])-np.array(bti[0:2])) \n",
    "\n",
    "        aemn_x = list(mean0_track[:,2]) \n",
    "        aemn_y = list(mean0_track[:,3])\n",
    "        aemn_t = forecast_periods\n",
    "        aemni = track_position_akima(aemn_x, aemn_y, aemn_t, obsti)\n",
    "        d_aemn_bt[indx] = np.linalg.norm(np.array(aemni[0:2])-np.array(bti[0:2]))\n",
    "        \n",
    "    # pack results to be returned from the algorithm\n",
    "    results =  { 'obs_positions': obs_positions, # list of observation positions\n",
    "                 'known_storm_position': known_storm_position, # list of known storm positions (processed from the observations)\n",
    "                 'error_wna': np.sum(d_obs_bt)/len(d_obs_bt)*1e-3, # average distance-error upon using the EGCTF algorithm\n",
    "                 'num_succ_cap_wna': np.sum(seen),  # number of successfull captures upon using the EGCTF algorithm\n",
    "                 'error_waemn' :  np.sum(d_aemn_bt)/len(d_aemn_bt)*1e-3,  # average distance-error upon using the baseline algorithm (AEMN-track only)\n",
    "                 'num_succ_cap_waemn': sum(d_aemn_bt<senFPr)[0],  # number of successfull captures upon using the baseline algorithm (AEMN-track only)\n",
    "                 'd_obs_bt': d_obs_bt, # list of distance errors of the captures at the observation times upon using the EGCTF algorithm\n",
    "                 'd_aemn_bt': d_aemn_bt, # list of distance errors of the captures at the observation times upon using the baseline (AEMN-track only) algorithm\n",
    "                 'seen': seen, # vector of seen (1) or not-seen (0) at the observation times\n",
    "                 'bt_positions': bt_positions} # best track positions at the observation times\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(ex, aemnTrack, bestTrack, algo_results):\n",
    "    \"\"\" Function which produces plots summarizing the results onto one plot per test-case. \"\"\"\n",
    "\n",
    "    ''' ALL RESULTS SUMMARY'''\n",
    "    %matplotlib notebook\n",
    "    #calling it a second time may prevent some graphics errors\n",
    "    %matplotlib notebook  \n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    levels = [0, 1, 2, 3, 4, 5]\n",
    "    colors = ['black', 'yellow', 'brown', 'green', 'blue']\n",
    "    cmap, norm = matplotlib.colors.from_levels_and_colors(levels, colors)\n",
    "\n",
    "    aemn_x = list(aemnTrack[:,2]) \n",
    "    aemn_y = list(aemnTrack[:,3])\n",
    "    aemn_t = forecast_periods\n",
    "    aemn_fine_t = np.linspace(0,max(forecast_periods),1000)\n",
    "    aemn_fine_x, aemn_fine_y, aemn__fine_t = track_position_akima(aemn_x, aemn_y, aemn_t, aemn_fine_t)\n",
    "\n",
    "    bt_x = list(bestTrack[:,2]) \n",
    "    bt_y = list(bestTrack[:,3])\n",
    "    bt_t = forecast_periods\n",
    "    bt_fine_t = np.linspace(0,max(forecast_periods),1000)\n",
    "    bt_fine_x, bt_fine_y, bt_fine_t = track_position_akima(bt_x, bt_y, bt_t, bt_fine_t)\n",
    "\n",
    "\n",
    "    fig, ((ax1, ax2), (ax6, ax7)) = plt.subplots(nrows=2, ncols=2, figsize=(13, 7), sharex ='row', sharey = 'row')\n",
    "\n",
    "    ax1.plot(obs_times, algo_results['d_aemn_bt']*1e-3, 'k.', label='AEMN')\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.text(0.35, 0.9, \"%0.2f\" % algo_results['error_waemn'], horizontalalignment='center', verticalalignment='center', transform=ax1.transAxes)\n",
    "\n",
    "    ax2.plot(obs_times, algo_results['d_obs_bt']*1e-3, 'r.', label='ALGO')\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.text(0.35, 0.9, \"%0.2f\" % algo_results['error_wna'], horizontalalignment='center', verticalalignment='center', transform=ax2.transAxes)\n",
    "\n",
    "    ax1.set_ylabel('Error Distance [km]')\n",
    "\n",
    "    ax1.set_xlabel('Time [hrs]')\n",
    "    ax2.set_xlabel('Time [hrs]')\n",
    "\n",
    "\n",
    "    for tn in range(0,nens):\n",
    "        ax6.plot(ensTracks[tn][:,2]*1e-6, ensTracks[tn][:,3]*1e-6, 'b--')\n",
    "    ax6.plot(aemnTrack[:,2]*1e-6, aemnTrack[:,3]*1e-6, 'c')\n",
    "    ax6.plot(bestTrack[:,2]*1e-6, bestTrack[:,3]*1e-6, 'k')\n",
    "    ax6.text(0.35, 0.9, str(algo_results['num_succ_cap_waemn']), horizontalalignment='center', verticalalignment='center', transform=ax6.transAxes)\n",
    "\n",
    "    ax7.plot(aemn_fine_x*1e-6, aemn_fine_y*1e-6, 'k--', bt_fine_x*1e-6, bt_fine_y*1e-6, 'k')\n",
    "    ax7.scatter(algo_results['obs_positions'][:,0]*1e-6, algo_results['obs_positions'][:,1]*1e-6, c = algo_results['seen'].flatten(), marker='s', cmap=cmap, norm=norm,)\n",
    "    ax7.text(0.35, 0.9, str(algo_results['num_succ_cap_wna']), horizontalalignment='center', verticalalignment='center', transform=ax7.transAxes)\n",
    "\n",
    "    ax6.set_ylabel('Position-Y 1e6 [m]')\n",
    "\n",
    "    ax6.set_xlabel('Position-X 1e6 [m]')\n",
    "    ax7.set_xlabel('Position-X 1e6 [m]')\n",
    "\n",
    "\n",
    "    fig.suptitle('ex:' + str(ex) + '  Sensor footprint radius:' + str(int(senFPr*1e-3)) + 'km', size=16)\n",
    "    plt.savefig('sim_data/' + str(ex)+'.png')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
